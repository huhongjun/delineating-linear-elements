{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifying a point cloud with a random forest using neighbourhood parameters in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 1. Set up python, including libraries and the Spyder IDE.\n",
    "\n",
    "To set up python we use a Python distribution which comes with a lot of\n",
    "libraries pre-installed called Anaconda. Anaconda is made with data science\n",
    "in mind and already contains many of the libraries we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1. Download and install Anaconda.\n",
    "Note. You can choose to install Python 2 or Python 3. I use Python 2\n",
    "(because software packages like ArcGIS use python 2), but as for as I know\n",
    "the exercise should also work in python 3.\n",
    "While Anaconda comes with many libraries already it does not always\n",
    "have every one needed. For this Anaconda comes with a package manager\n",
    "called conda. To use conda open a Anaconda command prompt (found in\n",
    "Start Menu > All Programs > Anaconda > Anaconda Prompt ) and type\n",
    "‘conda’ followed by a command. The command to install a new package is:\n",
    "‘conda install <package name>’. Generally it is a good idea to Google ‘conda\n",
    "<package name>’ to ﬁnd the most up to date version of the package avail-\n",
    "able through conda. Sometimes multiple versions of a package are available\n",
    "through conda from diﬀerent sources. Search through the Google results to\n",
    "ﬁnd the most appropriate one for your needs and copy the text found under\n",
    "‘To install this package with conda run:’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n chris python=2.7.12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2. Use Conda to install the ‘Shapely’ library.\n",
    "Anaconda also comes with an IDE (integrated development environment)\n",
    "called Spyder. Spyder (Scientiﬁc PYthon Development EnviRonment) is\n",
    "speciﬁcally made with scientiﬁc computing in mind and as such its interface\n",
    "is very similar to MATLAB. It features among other things an editor with\n",
    "syntax highlighting and code completion, a variable explorer and a debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install shapely=1.6.2\n",
    "pip install shapely=1.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3. Start up the Spyder IDE and familiarize yourself with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 2. Download airborne LiDAR data and prepare it for processing in Python.\n",
    "\n",
    "We will use the AHN3 (Actueel Hoogtebestand Nederland) dataset for\n",
    "our LiDAR data. This is a very recent dataset (it is actually still being\n",
    "scanned), which has a high point density and information on intensity and\n",
    "multiple returns. It is available at https://www.pdok.nl/nl/ahn3-downloads.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4. Download an AHN3 point cloud data tile.\n",
    "LAS is the conventional format airborne LiDAR data is stored in. This\n",
    "data is in zipped LAS format (LAZ) though and to use it we ﬁrst need to\n",
    "decompress it. The tool available for this task is called LASTools and can be\n",
    "downloaded from https://rapidlasso.com/lastools/. These tools are partly free\n",
    "and open source software (FOSS) and partly licensed. Careful when using\n",
    "the paid tools without a license, because LASTools will slightly distort the\n",
    "output after a certain point limit. You will be notiﬁed through the console\n",
    "when this happens. For now we don’t have to worry about this, since the\n",
    "tool we are going to use (laszip) is FOSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5. Download LASTools and open laszip.\n",
    "You can decompress the entire tile if you wish, but it will result in a very\n",
    "large LAS ﬁle. Often a research area is smaller than the tile. The output\n",
    "extent can be speciﬁed in laszip under clip input. There are two output\n",
    "formats available: LAS and ASCII. For processing LiDAR data in programs\n",
    "like ArcGIS the LAS format is needed. When using the data in Python it is\n",
    "easier to work with ASCII.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 6. Use laszip to decompress the point cloud data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 3. Visualize the point cloud using CloudCompare.\n",
    "Before we are going to use Python to process the point cloud data we\n",
    "want to inspect the point cloud to see if downloading and decompressing the\n",
    "data went well and to get a good overview of the data we are dealing with.\n",
    "A good FOSS program to visualize a point cloud (among many other very\n",
    "useful tools) is called CloudCompare. The software is available for download\n",
    "at http://www.danielgm.net/cc/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 7. Download CloudCompare and load in the point cloud.\n",
    "Because CloudCompare uses 32-bit ﬂoats to store the coordinates it can\n",
    "lose precision when using large coordinates (which is often the case when\n",
    "dealing with georeferenced point clouds, like AHN3). To avoid a loss in\n",
    "precision CloudCompare proposes to shift the coordinates temporarily so\n",
    "that the coordinates are closer to zero. When saving the point cloud the\n",
    "coordinates will be shifted back. It is advisable to use this shifting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 8. Explore the point cloud in CloudCompare.\n",
    "In CloudCompare you can also visualize the diﬀerent properties of the\n",
    "points, like the intensity and the number of returns. CloudCompare calls\n",
    "these scalar ﬁelds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 9. Visualize the intensity and the number of returns. \n",
    "Play around with diﬀerent color scales and diﬀerent display ranges (drag around\n",
    "the sliders in the display ranges tab)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 10. Have a look around at what other functionalities CloudCompare has."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 4. Import the point cloud into Python and do some basic computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note. In Python we will use a range of libraries. A short description will\n",
    "be provided, but for detailed instructions use the library documentation and\n",
    "Google.\n",
    "To read in the very large ASCII ﬁle we will use the pandas library (comes\n",
    "already installed with Anaconda). Pandas is a library that provides high\n",
    "performance and easy to use data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 11. Import pandas and use it to read in the point cloud csv\n",
    "ﬁle.\n",
    "Numpy (comes already installed with Anaconda) provides python with\n",
    "important functions and objects for scientiﬁc computing. One of the foremost\n",
    "functions it provides is the array object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 12. Import numpy and convert the X, Y and Z coordinates in\n",
    "the pandas DataFrame of the point cloud to a N×3 numpy array.\n",
    "Using these two formats we can do basically any calculation with the\n",
    "points necessary.\n",
    "Whether a point is a last return or not is a useful property of a point. To\n",
    "check this we can compare the return number with the number of returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 13. Create a new column in the DataFrame called last return.\n",
    "Loop through the points and set last return to true for the point where the\n",
    "return number is equal to the number of returns.\n",
    "Note. Looping through the points is by no means the fastest way to compute\n",
    "this, but it’s a good exercise for when looping through points is going to be\n",
    "necessary. If you want also try to compute this without looping.\n",
    "Note. If your point cloud is very large and the computation time gets annoy-\n",
    "ingly long just compute it for the ﬁrst n points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 5. Use a k-d tree data structure to compute nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When processing point clouds it’s often needed to compute the nearest\n",
    "neighbours of a point. For example when computing neighbourhood param-\n",
    "eters or when using a region growing algorithm. To eﬃciently compute these\n",
    "nearest points a data structure can be used. Diﬀerent data structures exist,\n",
    "including the k-d tree, octree and R-tree. The most eﬃcient data structure\n",
    "depends on the data and the application. We will us a k-d tree, but this is\n",
    "certainly not the only option.\n",
    "The python library SciPy (comes already installed with Anaconda) con-\n",
    "tains many functions for scientiﬁc computing. It includes a spatial module,\n",
    "which contains an algorithm for the construction of k-d trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 14. Import cKDTree from SciPy and use it to construct a k-d tree for the point cloud.\n",
    "Note. SciPy also has a KDTree function. The diﬀerence between cKDTree\n",
    "and KDTree is that KDTree is coded in pure python while cKDTree is coded\n",
    "in Cython (a version of python which gives python-like code C-like perfor-\n",
    "mance). Consequently cKDTree is signiﬁcantly faster than KDTree.\n",
    "Now that the k-d tree is constructed it can be queried for neighbours.\n",
    "This can be done in two ways: (i) loop over the points and query for each\n",
    "point separately, and (ii) query every point at once. Generally the former is\n",
    "more memory eﬃcient, while the latter is more CPU eﬃcient.\n",
    "Before we query for neighbours we need to deﬁne our neighbourhood.\n",
    "This can be done in three ways: (i) k nearest neighbours, (ii) spherical, and\n",
    "(iii) cylindrical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 15. Use the k-d tree to compute the neighbourhood of a point\n",
    "using the three diﬀerent neighbourhood deﬁnitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 6. Use a structure tensor to compute neighbourhood parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Use a k nearest neighbours neighbourhood. We are going to use the point\n",
    "neighbourhoods to describe the points in relation to surrounding. These\n",
    "parameters can then be used for a classiﬁcation.\n",
    "We will start with a few basic geometric properties of the neighbourhood:\n",
    "    =================\n",
    "where pi is the current point which is part of a point cloud P (a set of points\n",
    "{p1, p2, . . . , pn}), Ni is the neighbourhood of pi with points {q1, q2, . . . , qk},\n",
    "where q1 = p1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 16. Calculate these properties for a neighbourhood.\n",
    "To further describe the surface of the neighbourhood we will use a struc-\n",
    "ture tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 17. Read what the structure tensor is and how to interpret it\n",
    "on Wikipedia at https:// en.wikipedia.org/wiki/Structure tensor . More specif-\n",
    "ically what is written in the 3D structure tensor section https:// en.wikipedia.\n",
    "org/wiki/Structure tensor#The 3D structure tensor ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to compute this structure tensor we need to compute the eigenvalues\n",
    "(λ1, λ2, λ3) and eigenvectors of the covariance matrix of the points in the\n",
    "neighbourhood.\n",
    "Assignment 18. Use Numpy to compute the eigenvectors and eigenvalues\n",
    "of the covariance matrix of a neighbourhood. Tip: use the numpy.cov and\n",
    "numpy.linalg.eig functions.\n",
    "Note. The resulting eigenvectors and eigenvalues are not yet sorted. Sort\n",
    "them both based on the value of the eigenvalues, so that λ1 > λ2 > λ3\n",
    "Now we have everything we need to compute the following eight structure\n",
    "tensor features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 18. Use Numpy to compute the eigenvectors and eigenvalues\n",
    "of the covariance matrix of a neighbourhood. Tip: use the numpy.cov and\n",
    "numpy.linalg.eig functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 19. Compute the eight structure tensor features for a neigh-\n",
    "bourhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 20. Compute all neighbourhood parameters for all points in the\n",
    "point cloud.\n",
    "Note. For now don’t use a point cloud with too many points. The calculation\n",
    "of parameters can take a long time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective 7. Classify the point cloud using the parametrized points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all these extra parameters to describe each point we\n",
    "can use this to classify. Classiﬁcation can be done by a range of machine\n",
    "learning algorithms. A good python library for machine learning algorithms\n",
    "is called scikit-learn (comes already installed with Anaconda). This library\n",
    "contains functions for Support Vector Machines (SVM) and Random Forests\n",
    "(RF) and many more.\n",
    "To use a machine learning algorithm you need training and testing data to\n",
    "feed the machine. This can be pretty labour intensive to get. CloudCompare\n",
    "can be a good tool for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 21. Use CloudCompare to manually segment a part of your point cloud into diﬀerent classes (for example buildings, vegetation, ground,water, etc..). \n",
    "Tip: Use the segment tool to segment points belonging to a\n",
    "class from the main point cloud. Use the merge tool to merge all segments of\n",
    "a class together. Export the resulting point clouds separately per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 22. Import the class point clouds into python and merge them into one pandas DataFrame with a ‘class’ column containing the designated classes.\n",
    "We are going to use a random forest for classiﬁcation. A random forest is\n",
    "an algorithm that creates a range of decision trees based on random subsets\n",
    "of the data. These decision trees will all classify and the class that gets the\n",
    "most votes from the trees is used as the ﬁnal classiﬁcation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 23. Read up on random forests in python\n",
    "for example on http:// blog.yhat.com/ posts/ random-forests-in-python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 24. Train a random forest classiﬁer (from scikit-learn) with train data and use it to classify test data.\n",
    "To assess the accuracy of a classiﬁcation we can make a confusion matrix,\n",
    "which shows the actual classes against the predicted classes. Using this\n",
    "matrix we can calculate diﬀerent scores which describe the performance of\n",
    "our classiﬁer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 25. Create a accuracy assessment using a confusion matrix\n",
    "and corresponding precision, recall, accuracy, F1 and kappa scores.\n",
    "Another method to assess the performance of a classiﬁer is the ROC-\n",
    "curve. This curve can be made for each class. It shows the true positive rate\n",
    "plotted against the false positive rate at various decision thresholds. The area\n",
    "under a ROC-curve (AUC) is a measure for the performance of the classiﬁer\n",
    "for that class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 26. Create ROC-curves for the diﬀerent classes and compute\n",
    "the AUC.\n",
    "Now that we have an idea of the performance of the classiﬁer we can\n",
    "either use it to classify the rest of the points or if we are not satisﬁed with\n",
    "the accuracy we can try to improve the classiﬁer ﬁrst. This can be done by\n",
    "either changing the parameters of the classiﬁer (for example the number of\n",
    "trees in the random forest), by using a diﬀerent set of point features (for\n",
    "example by checking the feature importances and leaving out unimportant\n",
    "features), by improving the manually classiﬁed point clouds (if they are not\n",
    "yet perfect), or by using a diﬀerent machine learning algorithm altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 27. Make a classiﬁer you are satisﬁed with and use it to classify\n",
    "the entire point cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 28. Export the point cloud and visualize the classiﬁcation (in\n",
    "CloudCompare, ArcGIS or some other software). Explore the results and\n",
    "visually check if the classiﬁcation results seem good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
